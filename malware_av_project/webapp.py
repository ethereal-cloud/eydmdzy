from __future__ import annotations

import csv
import os
import json
import time
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, Iterator, List, Tuple

from flask import Flask, abort, render_template, request, send_file, url_for

from avscan.metrics import compute_confusion
from avscan.utils import iter_files, sha256_file
from avscan.yara_scanner import YaraEngine
from avscan.zircolite_runner import find_zircolite_path, parse_zircolite_hits, run_zircolite

BASE_DIR = Path(__file__).resolve().parent
OUTPUT_DIR = BASE_DIR / "outputs"
UPLOAD_DIR = OUTPUT_DIR / "uploads"

DEFAULT_SCAN_FORM = {
    "timeout": "20",
    "hash": True,
}

FILE_LIMIT = 200
SIGMA_LIMIT = 100

app = Flask(__name__)


def _parse_bool(value: str | None) -> bool:
    return str(value).lower() in {"1", "true", "yes", "on"}


def _safe_int(value: str | None, default: int) -> int:
    try:
        return int(str(value))
    except Exception:
        return default


def _job_id() -> str:
    stamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    return f"{stamp}_{time.time_ns() % 100000:05d}"


def _sanitize_relpath(name: str) -> Path:
    raw = Path(name)
    parts: List[str] = []
    for part in raw.parts:
        if part in ("", ".", ".."):
            continue
        if ":" in part:
            continue
        part = part.strip("/\\")
        if part:
            parts.append(part)
    return Path(*parts) if parts else Path(raw.name)


def _save_uploads(files: List[Any], dest_dir: Path) -> List[Path]:
    saved: List[Path] = []
    for f in files:
        if not f or not getattr(f, "filename", ""):
            continue
        rel = _sanitize_relpath(f.filename)
        target = dest_dir / rel
        target.parent.mkdir(parents=True, exist_ok=True)
        f.save(str(target))
        saved.append(target)
    return saved


def _iter_json_events(path: Path) -> Iterator[Dict[str, Any]]:
    suffix = path.suffix.lower()
    if suffix in {".jsonl", ".ndjson"}:
        with path.open("r", encoding="utf-8", errors="ignore") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    evt = json.loads(line)
                except Exception:
                    continue
                if isinstance(evt, dict):
                    yield evt
    elif suffix == ".json":
        try:
            data = json.loads(path.read_text(encoding="utf-8", errors="ignore"))
        except Exception:
            return
        if isinstance(data, list):
            for item in data:
                if isinstance(item, dict):
                    yield item
        elif isinstance(data, dict):
            yield data


def _parse_evtx_xml(xml: str) -> Dict[str, Any]:
    import xml.etree.ElementTree as ET

    try:
        root = ET.fromstring(xml)
    except Exception:
        return {}

    ns = {"e": "http://schemas.microsoft.com/win/2004/08/events/event"}

    def find_text(path: str) -> str | None:
        node = root.find(path, ns)
        return node.text if node is not None else None

    def find_attr(path: str, attr: str) -> str | None:
        node = root.find(path, ns)
        return node.get(attr) if node is not None else None

    event_id = find_text("./e:System/e:EventID")
    try:
        event_id_val: Any = int(event_id) if event_id and event_id.isdigit() else event_id
    except Exception:
        event_id_val = event_id

    system: Dict[str, Any] = {
        "EventID": event_id_val,
        "ProviderName": find_attr("./e:System/e:Provider", "Name"),
        "Channel": find_text("./e:System/e:Channel"),
        "Computer": find_text("./e:System/e:Computer"),
        "TimeCreated": find_attr("./e:System/e:TimeCreated", "SystemTime"),
        "EventRecordID": find_text("./e:System/e:EventRecordID"),
        "Task": find_text("./e:System/e:Task"),
        "Level": find_text("./e:System/e:Level"),
    }

    event_data: Dict[str, Any] = {}
    for node in root.findall("./e:EventData/e:Data", ns):
        name = node.get("Name") or "Data"
        value = node.text or ""
        if name in event_data:
            prev = event_data[name]
            if isinstance(prev, list):
                prev.append(value)
            else:
                event_data[name] = [prev, value]
        else:
            event_data[name] = value

    event: Dict[str, Any] = {
        "System": {k: v for k, v in system.items() if v is not None},
        "EventData": event_data,
    }

    for k, v in system.items():
        if v is not None:
            event[k] = v
    for k, v in event_data.items():
        event[k] = v

    return event


def _iter_evtx_events(path: Path) -> Iterator[Dict[str, Any]]:
    try:
        from Evtx.Evtx import Evtx
    except Exception as exc:
        raise RuntimeError("python-evtx is required to parse .evtx logs.") from exc

    with Evtx(str(path)) as evtx:
        for record in evtx.records():
            event = _parse_evtx_xml(record.xml())
            if event:
                yield event


def _iter_sigma_events(path: Path) -> Iterator[Dict[str, Any]]:
    suffix = path.suffix.lower()
    if suffix == ".evtx":
        yield from _iter_evtx_events(path)
    else:
        yield from _iter_json_events(path)


def _build_report(
    input_path: Path,
    yara_path: Path | None,
    sigma_path: Path | None,
    logs_path: Path | None,
    out_path: Path,
    compute_hash: bool,
    timeout: int,
) -> Dict[str, Any]:
    out_path.parent.mkdir(parents=True, exist_ok=True)
    report: Dict[str, Any] = {
        "meta": {
            "generated_at": datetime.now().isoformat(timespec="seconds"),
            "input": str(input_path),
            "yara_rules": str(yara_path) if yara_path else None,
            "sigma_rules": str(sigma_path) if sigma_path else None,
            "sigma_logs": str(logs_path) if logs_path else None,
            "out_path": str(out_path),
            "zircolite": None,
        },
        "files": [],
        "sigma_hits": [],
    }

    yara_engine = YaraEngine(yara_path) if yara_path else None

    file_list = list(iter_files(input_path, follow_symlinks=False))
    for fp in file_list:
        item: Dict[str, Any] = {
            "path": str(fp),
            "name": fp.name,
            "size": fp.stat().st_size if fp.exists() else None,
            "sha256": None,
            "yara": [],
            "is_malicious": 0,
        }
        if compute_hash:
            try:
                item["sha256"] = sha256_file(fp)
            except Exception:
                item["sha256"] = None

        if yara_engine:
            matches = yara_engine.scan_file(fp, timeout=timeout)
            item["yara"] = [
                {"rule": m.rule, "namespace": m.namespace, "tags": m.tags, "meta": m.meta}
                for m in matches
            ]
            if matches:
                item["is_malicious"] = 1

        report["files"].append(item)

    if sigma_path and logs_path and logs_path.exists():
        zircolite_path = find_zircolite_path(BASE_DIR)
        if not zircolite_path:
            raise RuntimeError(
                "Zircolite not found. Set ZIRCOLITE_PATH or place tools/zircolite/zircolite.py."
            )
        zircolite_out = out_path.with_name(out_path.stem + "_zircolite.json")
        exit_code, output = run_zircolite(
            zircolite_path=zircolite_path,
            log_path=logs_path,
            rules_path=sigma_path,
            output_path=zircolite_out,
            python_exe=os.environ.get("PYTHON_EXE", "python"),
        )
        report["meta"]["zircolite"] = {
            "path": str(zircolite_path),
            "output": str(zircolite_out),
            "exit_code": exit_code,
        }
        if output:
            report["meta"]["zircolite"]["message"] = output[:5000]
        if exit_code != 0:
            raise RuntimeError("Zircolite failed. Check report meta for details.")
        report["sigma_hits"] = parse_zircolite_hits(zircolite_out)

    out_path.write_text(json.dumps(report, ensure_ascii=False, indent=2), encoding="utf-8")
    return report


def _summarize_report(report: Dict[str, Any], elapsed: float) -> Dict[str, Any]:
    files = report.get("files", [])
    malicious = sum(1 for f in files if int(f.get("is_malicious", 0)) == 1)
    yara_hits = sum(len(f.get("yara", [])) for f in files)
    sigma_hits = len(report.get("sigma_hits", []))
    return {
        "files_scanned": len(files),
        "malicious": malicious,
        "yara_hits": yara_hits,
        "sigma_hits": sigma_hits,
        "elapsed": f"{elapsed:.2f}s",
        "report_path": report.get("meta", {}).get("out_path"),
    }


def _file_rows(report: Dict[str, Any]) -> Tuple[List[Dict[str, Any]], bool]:
    rows: List[Dict[str, Any]] = []
    files = report.get("files", [])
    truncated = len(files) > FILE_LIMIT
    for item in files[:FILE_LIMIT]:
        matches = [m.get("rule") for m in item.get("yara", []) if m.get("rule")]
        match_display = ", ".join(matches[:4])
        if len(matches) > 4:
            match_display += f" +{len(matches) - 4} more"
        rows.append(
            {
                "path": item.get("path"),
                "size": item.get("size"),
                "sha256": item.get("sha256"),
                "is_malicious": bool(item.get("is_malicious", 0)),
                "yara_count": len(matches),
                "yara_rules": match_display,
            }
        )
    return rows, truncated


def _sigma_rows(report: Dict[str, Any]) -> Tuple[List[Dict[str, Any]], bool]:
    rows: List[Dict[str, Any]] = []
    hits = report.get("sigma_hits", [])
    truncated = len(hits) > SIGMA_LIMIT
    for item in hits[:SIGMA_LIMIT]:
        rule_titles = [h.get("rule_title") for h in item.get("hits", []) if h.get("rule_title")]
        rows.append(
            {
                "line": item.get("line"),
                "rules": ", ".join(rule_titles[:4]) + (f" +{len(rule_titles) - 4} more" if len(rule_titles) > 4 else ""),
                "excerpt": json.dumps(item.get("event_excerpt", {}), ensure_ascii=False),
            }
        )
    return rows, truncated


def _compute_metrics(report_path: Path, groundtruth_path: Path) -> Dict[str, Any]:
    report = json.loads(report_path.read_text(encoding="utf-8", errors="ignore"))
    y_pred: Dict[str, int] = {}
    for it in report.get("files", []):
        name = it.get("name")
        if name:
            y_pred[name] = int(it.get("is_malicious", 0))

    y_true: Dict[str, int] = {}
    with groundtruth_path.open("r", encoding="utf-8", errors="ignore", newline="") as f:
        reader = csv.DictReader(f)
        for row in reader:
            n = row.get("name") or row.get("file") or row.get("filename")
            lbl = row.get("label") or row.get("malicious")
            if n is None or lbl is None:
                continue
            y_true[str(n)] = int(lbl)

    c = compute_confusion(y_true, y_pred)
    return {
        "tp": c.tp,
        "fp": c.fp,
        "fn": c.fn,
        "tn": c.tn,
        "precision": f"{c.precision:.4f}",
        "recall": f"{c.recall:.4f}",
        "f1": f"{c.f1:.4f}",
        "fpr": f"{c.fpr:.4f}",
    }


def _safe_output_path(rel_path: str) -> Path:
    target = (OUTPUT_DIR / rel_path).resolve()
    output_root = OUTPUT_DIR.resolve()
    if output_root not in target.parents and target != output_root:
        raise ValueError("Invalid output path.")
    return target


@app.route("/", methods=["GET"])
def index() -> str:
    return render_template(
        "index.html",
        scan_form=DEFAULT_SCAN_FORM.copy(),
        metrics_form={},
        scan_result=None,
        metrics_result=None,
        message=None,
        error=None,
    )


@app.route("/download/<path:rel_path>", methods=["GET"])
def download_report(rel_path: str):
    try:
        target = _safe_output_path(rel_path)
    except Exception:
        abort(404)
    if not target.exists() or not target.is_file():
        abort(404)
    return send_file(target, as_attachment=True)


@app.route("/scan", methods=["POST"])
def scan() -> str:
    scan_form = {
        "timeout": request.form.get("timeout", DEFAULT_SCAN_FORM["timeout"]),
        "hash": _parse_bool(request.form.get("hash")),
    }

    upload_root = UPLOAD_DIR / _job_id()
    input_dir = upload_root / "input"
    logs_dir = upload_root / "logs"

    input_files = request.files.getlist("input_dir") + request.files.getlist("input_files")
    saved_inputs = _save_uploads(input_files, input_dir)
    if not saved_inputs:
        return render_template(
            "index.html",
            scan_form=scan_form,
            metrics_form={},
            scan_result=None,
            metrics_result=None,
            message=None,
            error="Please select a folder or files to scan.",
        )

    default_yara = BASE_DIR / "rules" / "yara"
    yara_path = default_yara if default_yara.exists() else None

    if not yara_path:
        return render_template(
            "index.html",
            scan_form=scan_form,
            metrics_form={},
            scan_result=None,
            metrics_result=None,
            message=None,
            error="YARA rules not found. Put rules in rules/yara.",
        )

    logs_file = request.files.get("sigma_log")
    logs_path = None
    if logs_file and logs_file.filename:
        saved_logs = _save_uploads([logs_file], logs_dir)
        logs_path = saved_logs[0] if saved_logs else None

    sigma_path = None
    if logs_path:
        default_sigma = BASE_DIR / "rules" / "sigma"
        sigma_path = default_sigma if default_sigma.exists() else None
        if not sigma_path:
            return render_template(
                "index.html",
                scan_form=scan_form,
                metrics_form={},
                scan_result=None,
                metrics_result=None,
                message=None,
                error="Sigma rules not found. Put rules in rules/sigma.",
            )

    out_path = OUTPUT_DIR / f"web_report_{_job_id()}.json"
    timeout = _safe_int(scan_form.get("timeout"), 20)
    compute_hash = bool(scan_form.get("hash"))

    start = time.time()
    try:
        report = _build_report(
            input_path=input_dir,
            yara_path=yara_path,
            sigma_path=sigma_path,
            logs_path=logs_path,
            out_path=out_path,
            compute_hash=compute_hash,
            timeout=timeout,
        )
    except Exception as exc:
        return render_template(
            "index.html",
            scan_form=scan_form,
            metrics_form={},
            scan_result=None,
            metrics_result=None,
            message=None,
            error=f"Scan failed: {exc}",
        )

    elapsed = time.time() - start
    summary = _summarize_report(report, elapsed)
    summary["report_path"] = str(out_path)
    summary["download_url"] = url_for(
        "download_report",
        rel_path=str(out_path.relative_to(OUTPUT_DIR)).replace("\\", "/"),
    )
    file_rows, file_trunc = _file_rows(report)
    sigma_rows, sigma_trunc = _sigma_rows(report)
    scan_result = {
        "summary": summary,
        "files": file_rows,
        "sigma_hits": sigma_rows,
        "file_truncated": file_trunc,
        "sigma_truncated": sigma_trunc,
    }

    metrics_form = {
        "last_report": str(out_path.relative_to(OUTPUT_DIR)).replace("\\", "/"),
    }
    return render_template(
        "index.html",
        scan_form=scan_form,
        metrics_form=metrics_form,
        scan_result=scan_result,
        metrics_result=None,
        message="Scan complete. Report saved.",
        error=None,
    )


@app.route("/metrics", methods=["POST"])
def metrics() -> str:
    upload_root = UPLOAD_DIR / _job_id()
    metrics_dir = upload_root / "metrics"

    report_file = request.files.get("report_file")
    report_path = None
    if report_file and report_file.filename:
        saved_report = _save_uploads([report_file], metrics_dir / "report")
        report_path = saved_report[0] if saved_report else None
    else:
        last_report = request.form.get("last_report")
        if last_report:
            try:
                report_path = _safe_output_path(last_report)
            except Exception:
                report_path = None

    default_gt = BASE_DIR / "samples" / "groundtruth.csv"
    groundtruth_path = default_gt if default_gt.exists() else None

    if not report_path or not report_path.exists():
        return render_template(
            "index.html",
            scan_form=DEFAULT_SCAN_FORM.copy(),
            metrics_form={},
            scan_result=None,
            metrics_result=None,
            message=None,
            error="Report file not found. Upload a report or run a scan first.",
        )
    if not groundtruth_path or not groundtruth_path.exists():
        return render_template(
            "index.html",
            scan_form=DEFAULT_SCAN_FORM.copy(),
            metrics_form={},
            scan_result=None,
            metrics_result=None,
            message=None,
            error="Groundtruth CSV not found. Put it at samples/groundtruth.csv.",
        )

    try:
        metrics_result = _compute_metrics(report_path, groundtruth_path)
    except Exception as exc:
        return render_template(
            "index.html",
            scan_form=DEFAULT_SCAN_FORM.copy(),
            metrics_form={},
            scan_result=None,
            metrics_result=None,
            message=None,
            error=f"Metrics failed: {exc}",
        )

    return render_template(
        "index.html",
        scan_form=DEFAULT_SCAN_FORM.copy(),
        metrics_form={},
        scan_result=None,
        metrics_result=metrics_result,
        message="Metrics computed.",
        error=None,
    )


if __name__ == "__main__":
    app.run(debug=True)
